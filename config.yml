
lego_model_path: small_house.ldr

use_neural_network: yes
neural_network_model_path: ./tfmodels/sobel-unet-color-psize/model_val-loss-0-0677_val-acc-0-9760.h5.h5
use_color_vision: yes

environment:
  # Travel height for the robot arm.
  travel_height: 0.15  # Meters
  simulated: False

network:
  host:  # PC running the main program
    ip: 192.168.1.78
    port: 9001

  ur:  # Is set in the UR controller's network setup panel.
      ip: 192.168.1.198
      port: 30002  # Secondary client port is 30002

  raspi:  # Server running on the Raspberry Pi
    ip: 192.168.1.218
    port: 9002

brick_2x2_length: 31.8  # mm
brick_base_height: 19.2  # From bottom to root of the stud, mm
calibration_color: blue

# How strict to be about the colors calibrated.
# Larger values help with environment lighting changing after color calibration.
# Low values are more accurate but slight lighting changes may break the color vision.
# 0.75 recommended when 'use_neural_network' == yes and 0.4 otherwise.
color_strictness: 0.75  # 0..1

tcp:
  # Pose    x  y   z  rx  ry  rz
  # USE gripper z for the camera and do not add rotations to it
  gripper: [0, 0, 0.193, 0, 0, 0]
  camera: [0, -0.0625, 0.193, 0, 0, 0]


gripper:
  # Values represent how closed (0-100%) the gripper is
  open: 60
  open_tight: 65  # barely enough room to fit a 2x2 brick at its studs
  closed: 75
  force: 80

camera_parameters:
  resolution: [800, 600]
  awb_gains: [1.10, 2.32]
  awb_mode: "off"
  exposure_mode: "off"

grip_failure_detection:  # using Machine vision. Gripper feedback detection is always on.
  active: no
  roi:  # area between fingers (pixel ranges: heigth, width)
    - [0, 59]
    - [310, 480]

urscripts:
  robotiq_operate: legoassembler/urscripts/robotiq-2f-85_operate.script
  robotiq_get_pos: legoassembler/urscripts/robotiq-2f-85_get_actual_position.script

calibration_data:
  camera: camera_calibr.yml
  platform: platform_calibr.yml
  colors: color_definitions.yml